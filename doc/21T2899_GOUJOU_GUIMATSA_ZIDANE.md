# üéì Projet: Optimisation de la Fonction de Rosenbrock f(x,y) = (1-x)¬≤ + 100(y-x¬≤)¬≤

**Cours:** INF4127 - Optimisation 2  
**Institution:** Universit√© de Yaound√© 1  
**Ann√©e Acad√©mique:** 2024-2025  
**Encadreur:** Pr. MELATAGIA YONTA PAULIN

---

## üë• √âquipe du Projet

| Matricule | Nom | Pr√©nom |
|-----------|-----|--------|
| 22W2163 | DJATCHE-NKAMGANG | SYLVANO |
| 24F2456 | ESSUTHI MBANGUE | ANGE ARMEL |
| 19M2351 | TAGNE TALLA | IDRISS CHANEL |
| 21T2899 | GOUJOU GUIMATSA | ZIDANE |

---

## üìã Table des Mati√®res

1. [Introduction](#introduction)
2. [Description de la Fonction](#description-de-la-fonction)
3. [M√©thodologie](#m√©thodologie)
4. [Impl√©mentation](#impl√©mentation)

---

## üìñ Introduction

Ce projet porte sur l'optimisation num√©rique sans contraintes de la fonction de Rosenbrock, une fonction-test classique en optimisation. L'objectif est d'impl√©menter et de comparer diff√©rentes m√©thodes de descente pour trouver le minimum global de cette fonction.

## üéØ Description de la Fonction

### Fonction de Rosenbrock
\[ f(x, y) = (1 - x)^2 + 100(y - x^2)^2 \]

**Caract√©ristiques principales:**
- Minimum global en (1, 1) avec f(1,1) = 0
- Vall√©e √©troite et courb√©e ("banana valley")
- Conditionnement difficile
- Point critique unique

**Gradient:**
\[ \nabla f(x, y) = \begin{bmatrix} -2(1-x) - 400x(y-x^2) \\ 200(y-x^2) \end{bmatrix} \]

## üî¨ M√©thodologie

### 1. M√©thode de Gradient √† Pas Optimal
- Direction de descente: \( d_k = -\nabla f(x_k) \)
- Pas optimal d√©termin√© par recherche lin√©aire exacte
- M√©thode de la section dor√©e pour la minimisation unidimensionnelle

### 2. M√©thode de Gradient √† Pas Fixe
- Direction de descente: \( d_k = -\nabla f(x_k) \)
- Pas constant pr√©d√©fini
- Plusieurs valeurs de pas test√©es pour analyse comparative

### Crit√®res d'arr√™t:
- Norme du gradient: \( \|\nabla f(x_k)\| < \varepsilon \)
- Stagnation de la solution
- Nombre maximum d'it√©rations

## üíª Impl√©mentation

### Structure du Code
```python
# Fonctions principales
def rosenbrock(x, y)
def grad_rosenbrock(x, y)
def gradient_pas_optimal(f, grad_f, x0, y0, ...)
def gradient_pas_fixe(f, grad_f, x0, y0, pas, ...)

D√©pendances

    NumPy pour les calculs num√©riques

    Matplotlib pour la visualisation

    SymPy pour l'analyse symbolique
   
Observations Cl√©s

    M√©thode √† Pas Optimal:

        Convergence plus rapide que le pas fixe

        Ph√©nom√®ne de zigzag caract√©ristique dans la vall√©e

        Adaptation automatique du pas √† la courbure locale

    M√©thode √† Pas Fixe:

        Sensibilit√© √©lev√©e au choix du pas

        Convergence lente pour des pas trop petits

        Divergence possible pour des pas trop grands

        Comportement plus stable mais moins efficace

