# üéì TPE: Optimisation de la Fonction Quadratique f(x,y) = x¬≤ - y¬≤

**Cours:** INF4127 - Optimisation 2  
**Institution:** Universit√© de Yaound√© 1  
**Ann√©e Acad√©mique:** 2024-2025  
**Encadreur:** Pr. MELATAGIA YONTA PAULIN

---

## üë• √âquipe du Projet

| Matricule | Nom | Pr√©nom |
|-----------|-----|--------|
| 22W2163 | DJATCHE-NKAMGANG | SYLVANO |
| 24F2456 | ESSUTHI MBANGUE | ANGE ARMEL |
| 19M2351 | TAGNE TALLA | IDRISS CHANEL |
| 21T2899 | GOUJOU GUIMATSA | ZIDANE |

---

## üìå Description du Projet

Ce projet explore l'**optimisation num√©rique** appliqu√©e √† une fonction quadratique non convexe. L'objectif est de comparer deux strat√©gies d'optimisation :
- **Algorithme de gradient √† pas fixe**
- **Algorithme de gradient √† pas optimal (Steepest Descent)**

### Fonction √âtudi√©e

$$f(x, y) = x^2 - y^2$$

### Caract√©ristiques Principales

- **Type:** Fonction quadratique non convexe
- **Point critique:** Point selle en $(0, 0)$
- **Gradient:** $\nabla f(x, y) = \begin{pmatrix} 2x \\ -2y \end{pmatrix}$
- **Valeurs propres Hessienne:** $\lambda_1 = 2$ (minimisation), $\lambda_2 = -2$ (maximisation)

---

## üéØ Objectifs

1. Impl√©menter deux algorithmes de descente de gradient
2. Analyser leur comportement sur une fonction non convexe
3. Comparer les vitesses de convergence
4. √âtudier l'impact du point initial et du pas d'apprentissage
5. Visualiser les trajectoires d'optimisation

---

## üìÇ Structure du Projet

```
.
‚îú‚îÄ‚îÄ README.md                      # Ce fichier
‚îú‚îÄ‚îÄ TPE_Optimisation.ipynb         # Notebook principal avec tout le code
‚îú‚îÄ‚îÄ quadratic_optimal_multiple.png # Figure : trajectoires multiples (pas optimal)
‚îú‚îÄ‚îÄ quadratic_comparison.png       # Figure : comparaison des strat√©gies
‚îî‚îÄ‚îÄ requirements.txt               # D√©pendances Python
```

---

## üöÄ Utilisation

### Installation des D√©pendances

```bash
pip install -r requirements.txt
```

### Ex√©cution du Notebook

```bash
jupyter notebook TPE_Optimisation.ipynb
```

### Fichier requirements.txt

```
numpy>=1.21.0
matplotlib>=3.4.0
scipy>=1.7.0
pandas>=1.3.0
jupyter>=1.0.0
```

---

## üìä R√©sultats Principaux

### 1. Algorithme √† Pas Optimal

- **Convergence:** Atteinte en ~15-20 it√©rations depuis le point $(1.0, 1.0)$
- **Solution:** $x^* \approx (0, 0)$ avec $f(x^*) \approx 0$
- **Norme du gradient:** D√©croissance exponentielle

### 2. Algorithme √† Pas Fixe

| Pas | Convergence | It√©rations | Observation |
|-----|-------------|-----------|-------------|
| 0.01 | ‚úì Oui | ~200+ | Convergence lente mais stable |
| 0.25 | ‚úó Non | Divergence | Pas trop grand ‚Üí instabilit√© |

### 3. Sensibilit√© au Point Initial

Les trajectoires d'optimisation varient selon le point initial :
- **Points proches de l'origine:** Convergence rapide
- **Points √©loign√©s:** Convergence plus lente mais stable

---

## üîç Analyses R√©alis√©es

### Section 1: Th√©orie Math√©matique
- D√©finition de la fonction
- Calcul du gradient
- Identification des points critiques
- Analyse de la matrice Hessienne

### Section 2: Impl√©mentation Algorithmique
- **Fonction quadratique:** `f_quadratic(x)`
- **Gradient:** `grad_f_quadratic(x)`
- **Hessienne:** `hessian_f_quadratic(x)`
- **Gradient √† pas optimal:** `gradient_optimal_step()`
- **Gradient √† pas fixe:** `gradient_fixed_step()`

### Section 3: Visualisations
- Trajectoires d'optimisation sur les courbes de niveau
- Comparaison des strat√©gies (convergence, pas, gradient)
- Analyse de la sensibilit√© aux points initiaux

### Section 4: Tableaux Num√©riques
- R√©sultats d√©taill√©s it√©ration par it√©ration
- Comparaison synth√©tique des diff√©rentes approches

### Section 5: Analyse des R√©sultats
- Observations sur le comportement du gradient
- Vitesse de convergence (rapports successifs)
- Analyse sp√©cifique du point selle

---

## üí° Interpr√©tations Cl√©s

### Point Selle et Convergence

La fonction poss√®de un **point selle en (0,0)** o√π:
- Les m√©thodes de gradient convergent vers ce point
- C'est un minimum dans la direction $x$
- C'est un maximum dans la direction $y$

### Importance du Pas d'Apprentissage

| Aspect | Pas Fixe | Pas Optimal |
|--------|----------|------------|
| **R√©glage** | Manuel | Automatique |
| **Adaptabilit√©** | Fixe | Adaptatif |
| **Convergence** | D√©pend du pas | Plus robuste |
| **Co√ªt** | Faible | L√©g√®rement plus √©lev√© |

### Vitesse de Convergence

Le **pas optimal** montre une **convergence lin√©aire rapide** avec:
- Ratio de convergence moyen < 0.5
- Adaptation automatique √† la g√©om√©trie locale

---

## üìö R√©f√©rences Th√©oriques

1. **Nocedal, J., & Wright, S. J. (2006).** *Numerical Optimization* (2nd ed.). Springer.
2. **Boyd, S., & Vandenberghe, L. (2004).** *Convex Optimization*. Cambridge University Press.
3. **Cours INF4127 - Optimisation 2**, Universit√© de Yaound√© 1

---

## üéì Concepts Abord√©s

- ‚úÖ Optimisation sans contrainte
- ‚úÖ M√©thodes de descente de gradient
- ‚úÖ Recherche de pas unidimensionnelle
- ‚úÖ Points critiques et leur classification
- ‚úÖ Convergence et vitesse de convergence
- ‚úÖ Analyse de sensibilit√©

---

## ‚ö†Ô∏è Limitations et Observations

1. **Point selle:** Les m√©thodes de gradient convergent vers le point selle, qui n'est ni minimum ni maximum
2. **D√©pendance au point initial:** La convergence varie selon le d√©marrage
3. **Pas fixe:** N√©cessite un r√©glage manuel pour √©viter divergence ou convergence lente
4. **M√©thodes avanc√©es:** N√©cessit√© de techniques comme Newton modifi√© pour √©chapper aux points selles

---

## üîÆ Am√©liorations Futures

- [ ] Impl√©menter la m√©thode de Newton
- [ ] Ajouter des m√©thodes quasi-Newton (BFGS)
- [ ] √âtudier les m√©thodes de momentum (SGD avec momentum)
- [ ] Analyser d'autres types de points critiques
- [ ] G√©n√©raliser √† des dimensions sup√©rieures

---

## üìù Notes pour le Professeur

Ce projet d√©montre une compr√©hension approfondie de:

1. **Th√©orie:** Formulation math√©matique correcte de la fonction et de ses propri√©t√©s
2. **Impl√©mentation:** Code Python structur√© et bien comment√©
3. **Exp√©rimentation:** Tests syst√©matiques avec plusieurs configurations
4. **Analyse:** Interpr√©tation nuanc√©e des r√©sultats et limitations
5. **Visualisation:** Graphiques clairs pour communiquer les r√©sultats

---

## üìß Contact

Pour toute question sur ce projet, veuillez contacter les membres de l'√©quipe mentionn√©s ci-dessus.

---

**Derni√®re mise √† jour:** Novembre 2025

